(window.webpackJsonp=window.webpackJsonp||[]).push([[98],{475:function(s,t,a){"use strict";a.r(t);var n=a(11),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h2",{attrs:{id:"面试题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#面试题"}},[s._v("#")]),s._v(" 面试题")]),s._v(" "),t("p",[s._v("如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？")]),s._v(" "),t("h2",{attrs:{id:"面试官心理分析"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#面试官心理分析"}},[s._v("#")]),s._v(" 面试官心理分析")]),s._v(" "),t("p",[s._v("你看这问法，其实本质针对的场景，都是说，可能你的消费端出了问题，不消费了；或者消费的速度极其慢。接着就坑爹了，可能你的消息队列集群的磁盘都快写满了，都没人消费，这个时候怎么办？或者是这整个就积压了几个小时，你这个时候怎么办？或者是你积压的时间太长了，导致比如 RabbitMQ 设置了消息过期时间后就没了怎么办？")]),s._v(" "),t("p",[s._v("所以就这事儿，其实线上挺常见的，一般不出，一出就是大 case。一般常见于，举个例子，消费端每次消费之后要写 mysql，结果 mysql 挂了，消费端 hang 那儿了，不动了；或者是消费端出了个什么岔子，导致消费速度极其慢。")]),s._v(" "),t("h2",{attrs:{id:"面试题剖析"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#面试题剖析"}},[s._v("#")]),s._v(" 面试题剖析")]),s._v(" "),t("p",[s._v("关于这个事儿，我们一个一个来梳理吧，先假设一个场景，我们现在消费端出故障了，然后大量消息在 mq 里积压，现在出事故了，慌了。")]),s._v(" "),t("h3",{attrs:{id:"大量消息在-mq-里积压了几个小时了还没解决"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#大量消息在-mq-里积压了几个小时了还没解决"}},[s._v("#")]),s._v(" 大量消息在 mq 里积压了几个小时了还没解决")]),s._v(" "),t("p",[s._v("几千万条数据在 MQ 里积压了七八个小时，从下午 4 点多，积压到了晚上 11 点多。这个是我们真实遇到过的一个场景，确实是线上故障了，这个时候要不然就是修复 consumer 的问题，让它恢复消费速度，然后傻傻的等待几个小时消费完毕。这个肯定不能在面试的时候说吧。")]),s._v(" "),t("p",[s._v("一个消费者一秒是 1000 条，一秒 3 个消费者是 3000 条，一分钟就是 18 万条。所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概 1 小时的时间才能恢复过来。")]),s._v(" "),t("p",[s._v("一般这个时候，只能临时紧急扩容了，具体操作步骤和思路如下：")]),s._v(" "),t("ul",[t("li",[s._v("先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。")]),s._v(" "),t("li",[s._v("新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。")]),s._v(" "),t("li",[s._v("然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，"),t("strong",[s._v("消费之后不做耗时的处理")]),s._v("，直接均匀轮询写入临时建立好的 10 倍数量的 queue。")]),s._v(" "),t("li",[s._v("接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。")]),s._v(" "),t("li",[s._v("等快速消费完积压数据之后，"),t("strong",[s._v("得恢复原先部署的架构")]),s._v("，"),t("strong",[s._v("重新")]),s._v("用原先的 consumer 机器来消费消息。")])]),s._v(" "),t("h3",{attrs:{id:"mq-中的消息过期失效了"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#mq-中的消息过期失效了"}},[s._v("#")]),s._v(" mq 中的消息过期失效了")]),s._v(" "),t("p",[s._v("假设你用的是 RabbitMQ，RabbtiMQ 是可以设置过期时间的，也就是 TTL。如果消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在 mq 里，而是"),t("strong",[s._v("大量的数据会直接搞丢")]),s._v("。")]),s._v(" "),t("p",[s._v("这个情况下，就不是说要增加 consumer 消费积压的消息，因为实际上没啥积压，而是丢了大量的消息。我们可以采取一个方案，就是"),t("strong",[s._v("批量重导")]),s._v("，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上 12 点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了。")]),s._v(" "),t("p",[s._v("假设 1 万个订单积压在 mq 里面，没有处理，其中 1000 个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 mq 里去再补一次。")]),s._v(" "),t("h3",{attrs:{id:"mq-都快写满了"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#mq-都快写满了"}},[s._v("#")]),s._v(" mq 都快写满了")]),s._v(" "),t("p",[s._v("如果消息积压在 mq 里，你很长时间都没有处理掉，此时导致 mq 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，"),t("strong",[s._v("消费一个丢弃一个，都不要了")]),s._v("，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。")]),s._v(" "),t("hr"),s._v(" "),t("p",[s._v("对于 RocketMQ，官方针对消息积压问题，提供了解决方案。")]),s._v(" "),t("h3",{attrs:{id:"_1-提高消费并行度"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-提高消费并行度"}},[s._v("#")]),s._v(" 1. 提高消费并行度")]),s._v(" "),t("p",[s._v("绝大部分消息消费行为都属于 IO 密集型，即可能是操作数据库，或者调用 RPC，这类消费行为的消费速度在于后端数据库或者外系统的吞吐量，通过增加消费并行度，可以提高总的消费吞吐量，但是并行度增加到一定程度，反而会下降。所以，应用必须要设置合理的并行度。 如下有几种修改消费并行度的方法：")]),s._v(" "),t("p",[s._v("同一个 ConsumerGroup 下，通过增加 Consumer 实例数量来提高并行度（需要注意的是超过订阅队列数的 Consumer 实例无效）。可以通过加机器，或者在已有机器启动多个进程的方式。\n提高单个 Consumer 的消费并行线程，通过修改参数 consumeThreadMin、consumeThreadMax 实现。")]),s._v(" "),t("h3",{attrs:{id:"_2-批量方式消费"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-批量方式消费"}},[s._v("#")]),s._v(" 2. 批量方式消费")]),s._v(" "),t("p",[s._v("某些业务流程如果支持批量方式消费，则可以很大程度上提高消费吞吐量，例如订单扣款类应用，一次处理一个订单耗时 1 s，一次处理 10 个订单可能也只耗时 2 s，这样即可大幅度提高消费的吞吐量，通过设置 consumer 的 consumeMessageBatchMaxSize 返个参数，默认是 1，即一次只消费一条消息，例如设置为 N，那么每次消费的消息数小于等于 N。")]),s._v(" "),t("h3",{attrs:{id:"_3-跳过非重要消息"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-跳过非重要消息"}},[s._v("#")]),s._v(" 3. 跳过非重要消息")]),s._v(" "),t("p",[s._v("发生消息堆积时，如果消费速度一直追不上发送速度，如果业务对数据要求不高的话，可以选择丢弃不重要的消息。例如，当某个队列的消息数堆积到 100000 条以上，则尝试丢弃部分或全部消息，这样就可以快速追上发送消息的速度。示例代码如下：")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumeConcurrentlyStatus")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("consumeMessage")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("List")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MessageExt")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" msgs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumeConcurrentlyContext")]),s._v(" context"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("long")]),s._v(" offset "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" msgs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("get")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getQueueOffset")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),s._v(" maxOffset "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("\n            msgs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("get")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getProperty")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Message")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("PROPERTY_MAX_OFFSET")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("long")]),s._v(" diff "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Long")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("parseLong")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("maxOffset"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" offset"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("diff "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// TODO 消息堆积情况的特殊处理")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumeConcurrentlyStatus")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("CONSUME_SUCCESS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// TODO 正常消费过程")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumeConcurrentlyStatus")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("CONSUME_SUCCESS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br")])]),t("h3",{attrs:{id:"_4-优化每条消息消费过程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-优化每条消息消费过程"}},[s._v("#")]),s._v(" 4. 优化每条消息消费过程")]),s._v(" "),t("p",[s._v("举例如下，某条消息的消费过程如下：")]),s._v(" "),t("ul",[t("li",[s._v("根据消息从 DB 查询【数据 1】")]),s._v(" "),t("li",[s._v("根据消息从 DB 查询【数据 2】")]),s._v(" "),t("li",[s._v("复杂的业务计算")]),s._v(" "),t("li",[s._v("向 DB 插入【数据 3】")]),s._v(" "),t("li",[s._v("向 DB 插入【数据 4】")])]),s._v(" "),t("p",[s._v("这条消息的消费过程中有 4 次与 DB 的 交互，如果按照每次 5ms 计算，那么总共耗时 20ms，假设业务计算耗时 5ms，那么总过耗时 25ms，所以如果能把 4 次 DB 交互优化为 2 次，那么总耗时就可以优化到 15ms，即总体性能提高了 40%。所以应用如果对时延敏感的话，可以把 DB 部署在 SSD 硬盘，相比于 SCSI 磁盘，前者的 RT 会小很多。")])])}),[],!1,null,null,null);t.default=e.exports}}]);